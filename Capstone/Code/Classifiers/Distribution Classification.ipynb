{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chi/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from ThematicTextClassify.TextClassifier import *\n",
    "from ThematicTextClassify.Preprocessing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "301"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df =pd.read_csv('Categorized_Links.csv')\n",
    "# add the title and description column together to form a text document\n",
    "df['Text'] = df['Title']+ df['Description']\n",
    "df = df.dropna(subset= ['Text'], axis = 0)\n",
    "\n",
    "# preprocess the newly defined Text column\n",
    "# preprocess_text is a function I build and saved in TextClassifier.py\n",
    "\n",
    "df['Processed Text'] = df['Text'].map(preprocess_text)\n",
    "\n",
    "df['processed_string'] =  [' '.join(text) for text in df['Processed Text']]\n",
    "\n",
    "df['Class'] = \"\"\n",
    "df['Class'] = df.apply(lambda df: 'Distribution' if (df['Category'] == 'Distribution') else df['Class'], axis =1)\n",
    "df['Class'] = df.apply(lambda df: 'Other' if (df['Category'] != 'Distribution') else df['Class'], axis =1)\n",
    "df = df.reset_index(drop=True)\n",
    "df = df.sort_values('Class')\n",
    "df = df.reset_index(drop=True)\n",
    "df = df.drop_duplicates(['Link'],keep= 'first')\n",
    "df = df.reset_index(drop=True)\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_train, text_test, class_train, class_test = train_test_split(df,\n",
    "                                                    df['Class'],\n",
    "                                                    test_size=0.15, \n",
    "                                                    random_state=5131)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining Classifier Predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data to be classified \n",
    "full = pd.read_csv(\"NewData.csv\")\n",
    "\n",
    "# combine the title and description as text as our document\n",
    "full['Text'] = full['Title'] +full['Description']\n",
    "full['Processed Text'] = full['Text'].map(preprocess_text)\n",
    "full['processed_string'] =  [' '.join(text) for text in full['Processed Text']]\n",
    "full = full.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "full['Class'] = feature_pipe(CountVectorizer(max_df= 0.75, min_df =1, ngram_range = (1,3)),MultinomialNB(alpha=0.75), text_train, class_train, full )\n",
    "model1 = full[full['Class'] == 'Distribution']\n",
    "\n",
    "\n",
    "full['Class'] = feature_pipe(CountVectorizer(max_df= 0.25, min_df =3, ngram_range = (1,2)),LinearSVC(C=0.1), text_train, class_train, full)\n",
    "model2 = full[full['Class'] == 'Distribution']\n",
    "\n",
    "\n",
    "\n",
    "full['Class'] = feature_pipe(TfidfVectorizer(max_df= 0.25, min_df =3, ngram_range = (1,3)),LinearSVC(C=0.01), text_train, class_train, full)\n",
    "model3 = full[full['Class'] == 'Distribution']\n",
    "\n",
    "\n",
    "full['Class'] = feature_pipe(TfidfVectorizer(max_df= 0.75, min_df =3, ngram_range = (1,1)),XGBClassifier(max_depth = 7, seed = 2, random_state=1995,colsample_bytree=0.3, subsample=0.7), text_train, class_train, full)\n",
    "model4 = full[full['Class'] == 'Distribution']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of classified data set before dropping duplicates:  387\n",
      "Length of classified data set after dropping duplicates:  242\n"
     ]
    }
   ],
   "source": [
    "frames = [model1, model2, model3, model4]\n",
    "\n",
    "result_frame = pd.concat(frames)\n",
    "print(\"Length of classified data set before dropping duplicates: \", len(result_frame))\n",
    "result_frame = result_frame.drop_duplicates(['Link'],keep= 'last')\n",
    "print(\"Length of classified data set after dropping duplicates: \", len(result_frame))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "distributioncsv = result_frame[['Title', 'Description', 'Link', 'Class']]\n",
    "distributioncsv.to_csv('Distribution.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Description</th>\n",
       "      <th>Link</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1445</th>\n",
       "      <td>Eating out – How often and why</td>\n",
       "      <td>Eating out at restaurants or purchasing takeou...</td>\n",
       "      <td>https://www150.statcan.gc.ca/n1/en/catalogue/1...</td>\n",
       "      <td>Distribution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1446</th>\n",
       "      <td>Eating out: Nutrition information on menus and...</td>\n",
       "      <td>Being able to make informed food choices benef...</td>\n",
       "      <td>https://www150.statcan.gc.ca/n1/en/catalogue/1...</td>\n",
       "      <td>Distribution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1509</th>\n",
       "      <td>Eating out – How often and why</td>\n",
       "      <td>Eating out at restaurants or purchasing takeo...</td>\n",
       "      <td>https://www150.statcan.gc.ca/n1/pub/11-627-m/1...</td>\n",
       "      <td>Distribution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1510</th>\n",
       "      <td>Eating out: Nutrition information on menus and...</td>\n",
       "      <td>Being able to make informed food choices bene...</td>\n",
       "      <td>https://www150.statcan.gc.ca/n1/pub/11-627-m/1...</td>\n",
       "      <td>Distribution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1605</th>\n",
       "      <td>Nutritional information on packaged foods</td>\n",
       "      <td>The purpose of the 2016 General Social Survey...</td>\n",
       "      <td>https://www150.statcan.gc.ca/n1/pub/11-627-m/1...</td>\n",
       "      <td>Distribution</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Title  \\\n",
       "1445                     Eating out – How often and why   \n",
       "1446  Eating out: Nutrition information on menus and...   \n",
       "1509                     Eating out – How often and why   \n",
       "1510  Eating out: Nutrition information on menus and...   \n",
       "1605          Nutritional information on packaged foods   \n",
       "\n",
       "                                            Description  \\\n",
       "1445  Eating out at restaurants or purchasing takeou...   \n",
       "1446  Being able to make informed food choices benef...   \n",
       "1509   Eating out at restaurants or purchasing takeo...   \n",
       "1510   Being able to make informed food choices bene...   \n",
       "1605   The purpose of the 2016 General Social Survey...   \n",
       "\n",
       "                                                   Link         Class  \n",
       "1445  https://www150.statcan.gc.ca/n1/en/catalogue/1...  Distribution  \n",
       "1446  https://www150.statcan.gc.ca/n1/en/catalogue/1...  Distribution  \n",
       "1509  https://www150.statcan.gc.ca/n1/pub/11-627-m/1...  Distribution  \n",
       "1510  https://www150.statcan.gc.ca/n1/pub/11-627-m/1...  Distribution  \n",
       "1605  https://www150.statcan.gc.ca/n1/pub/11-627-m/1...  Distribution  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distributioncsv.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting Up Training Data, Holdout, and New data to be Classified (CountVectorizer)\n",
    "* Note: It is not likely to have individual vectorizer for each model. Therefore we would use countvectorizer with the most popular tuning parameters given from the best models above (optmized using GridSearchCv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Data \n",
    "countvect = CountVectorizer(max_df= 0.75, min_df =3, ngram_range = (1,2))\n",
    "X_train = countvect.fit_transform(text_train['processed_string'])\n",
    "X_train = X_train.toarray()\n",
    "y_train = class_train.replace(to_replace = \"Distribution\", value = 1)\n",
    "y_train = y_train.replace(to_replace = \"Other\", value = 0)\n",
    "y_train = y_train.values\n",
    "\n",
    "X_test = countvect.transform(text_test['processed_string'])\n",
    "X_test = X_test.toarray()\n",
    "\n",
    "y_test = class_test.replace(to_replace = \"Distribution\", value = 1)\n",
    "y_test  = y_test.replace(to_replace = \"Other\", value = 0)\n",
    "y_test  = y_test.values\n",
    "\n",
    "X_full = countvect.transform(full['processed_string'])\n",
    "X_full = X_full.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacked Classifier (CountVectorizer)\n",
    "## Using Logistic Regression as meta_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-fold cross validation:\n",
      "\n",
      "5-fold cross validated Accuracy: 0.66 (+/- 0.04) [Multinomial Naive Bayes]\n",
      "5-fold cross validated Accuracy: 0.91 (+/- 0.03) [Logistic Regression]\n",
      "5-fold cross validated Accuracy: 0.91 (+/- 0.04) [Linear SVC]\n",
      "5-fold cross validated Accuracy: 0.87 (+/- 0.01) [Random Forest Classifier]\n",
      "5-fold cross validated Accuracy: 0.90 (+/- 0.03) [XGBoost]\n",
      "5-fold cross validated Accuracy: 0.91 (+/- 0.03) [StackingClassifier]\n",
      "\n",
      "\n",
      "Stacked Classifier (CountVect) Clasification Report (Logisti Regression Meta Classifier)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Distribution       0.50      0.33      0.40         9\n",
      "       Other       0.85      0.92      0.88        37\n",
      "\n",
      "    accuracy                           0.80        46\n",
      "   macro avg       0.68      0.63      0.64        46\n",
      "weighted avg       0.78      0.80      0.79        46\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from ThematicTextClassify.EnsembleClassifiers import *\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "stack_clf1 = MultinomialNB(alpha=0.75)\n",
    "stack_clf2 = LogisticRegression(C=0.5, penalty = 'l2')\n",
    "stack_clf3 = SVC(kernel='linear', C= 0.1, probability=True)\n",
    "stack_clf4 = RandomForestClassifier(max_depth =4, n_estimators = 200, random_state = 2)\n",
    "stack_clf5 = XGBClassifier(max_depth = 5, seed = 1, random_state=1995,colsample_bytree=0.3, subsample=0.7)\n",
    "\n",
    "meta_clf = LogisticRegression(C=1.0, penalty = 'l2')\n",
    "sclf_log = StackingCVClassifier(classifiers=[stack_clf1, stack_clf2, stack_clf3, stack_clf4, stack_clf5],\n",
    "                          use_probas=True,\n",
    "                          meta_classifier=meta_clf)\n",
    "classifiers = [stack_clf1, stack_clf2, stack_clf3, stack_clf4,stack_clf5, sclf_log]\n",
    "classifier_names = ['Multinomial Naive Bayes', 'Logistic Regression', 'Linear SVC', 'Random Forest Classifier', 'XGBoost','StackingClassifier']\n",
    "\n",
    "\n",
    "# Acuracy function (5-fold Cross validated)\n",
    "scoring(classifiers, classifier_names, X_train, y_train)\n",
    "\n",
    "# Predicting new data \n",
    "sclf_log = sclf_log.fit(X_train,y_train)\n",
    "prediction_results_int = sclf_log.predict(X_test)\n",
    "prediction_results = []\n",
    "\n",
    "for i in prediction_results_int:\n",
    "    if i == 1:\n",
    "        prediction_results.append('Distribution')\n",
    "    else:\n",
    "        prediction_results.append('Other')\n",
    "        \n",
    "# Print out Classification report\n",
    "print(\"\\n\")\n",
    "print(\"Stacked Classifier (CountVect) Clasification Report (Logisti Regression Meta Classifier)\")\n",
    "print(classification_report(class_test.tolist(), prediction_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacked Classifier (CountVectorizer)\n",
    "## Using XGboost as the Meta Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-fold cross validation:\n",
      "\n",
      "5-fold cross validated Accuracy: 0.66 (+/- 0.04) [Multinomial Naive Bayes]\n",
      "5-fold cross validated Accuracy: 0.91 (+/- 0.03) [Logistic Regression]\n",
      "5-fold cross validated Accuracy: 0.91 (+/- 0.04) [Linear SVC]\n",
      "5-fold cross validated Accuracy: 0.87 (+/- 0.01) [Random Forest Classifier]\n",
      "5-fold cross validated Accuracy: 0.90 (+/- 0.03) [XGBoost]\n",
      "5-fold cross validated Accuracy: 0.91 (+/- 0.04) [StackingClassifier]\n",
      "\n",
      "\n",
      "Stacked Classifier (CountVect) Clasification Report (XGBoost as Meta Classifier)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Distribution       0.50      0.33      0.40         9\n",
      "       Other       0.85      0.92      0.88        37\n",
      "\n",
      "    accuracy                           0.80        46\n",
      "   macro avg       0.68      0.63      0.64        46\n",
      "weighted avg       0.78      0.80      0.79        46\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from ThematicTextClassify.EnsembleClassifiers import *\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "stack_clf1 = MultinomialNB(alpha=0.75)\n",
    "stack_clf2 = LogisticRegression(C=0.5, penalty = 'l2')\n",
    "stack_clf3 = SVC(kernel='linear', C= 0.1, probability=True)\n",
    "stack_clf4 = RandomForestClassifier(max_depth =4, n_estimators = 200, random_state = 2)\n",
    "stack_clf5 = XGBClassifier(max_depth = 5, seed = 1, random_state=1995,colsample_bytree=0.3, subsample=0.7)\n",
    "\n",
    "meta_clf = XGBClassifier(max_depth = 5, seed = 1, random_state=1995,colsample_bytree=0.3, subsample=0.7)\n",
    "\n",
    "sclf_XGB = StackingCVClassifier(classifiers=[stack_clf1, stack_clf2, stack_clf3, stack_clf4, stack_clf5],\n",
    "                          use_probas=True,\n",
    "                          meta_classifier=meta_clf)\n",
    "classifiers = [stack_clf1, stack_clf2, stack_clf3, stack_clf4, stack_clf5, sclf_XGB]\n",
    "classifier_names = ['Multinomial Naive Bayes', 'Logistic Regression', 'Linear SVC', 'Random Forest Classifier', 'XGBoost','StackingClassifier']\n",
    "\n",
    "# Acuracy function (5-fold Cross validated)\n",
    "scoring(classifiers, classifier_names, X_train, y_train)\n",
    "\n",
    "# Predicting new data \n",
    "sclf_XGB = sclf_XGB.fit(X_train,y_train)\n",
    "prediction_results_int = sclf_XGB.predict(X_test)\n",
    "prediction_results = []\n",
    "\n",
    "for i in prediction_results_int:\n",
    "    if i == 1:\n",
    "        prediction_results.append('Distribution')\n",
    "    else:\n",
    "        prediction_results.append('Other')\n",
    "        \n",
    "# Print Classification report\n",
    "print(\"\\n\")\n",
    "print(\"Stacked Classifier (CountVect) Clasification Report (XGBoost as Meta Classifier)\")\n",
    "print(classification_report(class_test.tolist(), prediction_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voting Classifier (CountVectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-fold cross validation:\n",
      "\n",
      "5-fold cross validated Accuracy: 0.66 (+/- 0.04) [Multinomial Naive Bayes]\n",
      "5-fold cross validated Accuracy: 0.91 (+/- 0.03) [Logistic Regression]\n",
      "5-fold cross validated Accuracy: 0.91 (+/- 0.03) [Linear SVC]\n",
      "5-fold cross validated Accuracy: 0.87 (+/- 0.01) [Random Forest Classifier]\n",
      "5-fold cross validated Accuracy: 0.90 (+/- 0.03) [XGBoost]\n",
      "5-fold cross validated Accuracy: 0.92 (+/- 0.03) [VotingClassifier]\n",
      "\n",
      "\n",
      "Voting Classifier (CountVect) Clasification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Distribution       0.50      0.33      0.40         9\n",
      "       Other       0.85      0.92      0.88        37\n",
      "\n",
      "    accuracy                           0.80        46\n",
      "   macro avg       0.68      0.63      0.64        46\n",
      "weighted avg       0.78      0.80      0.79        46\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vote_clf1 = MultinomialNB(alpha=0.75)\n",
    "vote_clf2 = LogisticRegression(C=0.5, penalty = 'l2')\n",
    "vote_clf3 = LinearSVC(C=0.1)\n",
    "vote_clf4 = RandomForestClassifier(max_depth =4, n_estimators = 200, random_state = 3)\n",
    "vote_clf5 =  XGBClassifier(max_depth = 5, seed = 1, random_state=1995,colsample_bytree=0.3, subsample=0.7)\n",
    "\n",
    "eclf1 = VotingClassifier(estimators=[('Multinomial Naive Bayes', vote_clf1), ('Logistic Regression Classifier', vote_clf2), ('LinearSVC', vote_clf3), ('RandomForestClassifier', vote_clf4), ('XGBoost', vote_clf5)], voting='hard')\n",
    "eclf1 = eclf1.fit(X_train, y_train)\n",
    "\n",
    "classifiers = [vote_clf1, vote_clf2, vote_clf3, vote_clf4, vote_clf5, eclf1]\n",
    "classifier_names = ['Multinomial Naive Bayes', 'Logistic Regression', 'Linear SVC', 'Random Forest Classifier','XGBoost', 'VotingClassifier']\n",
    "\n",
    "# Acuracy function (5-fold Cross validated)\n",
    "scoring(classifiers, classifier_names, X_train, y_train)\n",
    "\n",
    "# Predicting new data \n",
    "predicted = eclf1.predict(X_test)\n",
    "eclf1.score(X_test, y_test)\n",
    "\n",
    "pred_results = []\n",
    "for i in predicted:\n",
    "    if i == 1:\n",
    "        pred_results.append('Distribution')\n",
    "    else:\n",
    "        pred_results.append('Other')\n",
    "        \n",
    "# Print Classification report\n",
    "print(\"\\n\")\n",
    "print(\"Voting Classifier (CountVect) Clasification Report\")\n",
    "print(classification_report(class_test.tolist(),pred_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting Up Data (tfidfVectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Data \n",
    "tfidf = TfidfVectorizer(max_df= 0.5, min_df =3, ngram_range = (1,2))\n",
    "X_train = tfidf.fit_transform(text_train['processed_string'])\n",
    "X_train = X_train.toarray()\n",
    "y_train = class_train.replace(to_replace = \"Distribution\", value = 1)\n",
    "y_train = y_train.replace(to_replace = \"Other\", value = 0)\n",
    "y_train = y_train.values\n",
    "\n",
    "X_test = tfidf.transform(text_test['processed_string'])\n",
    "X_test = X_test.toarray()\n",
    "\n",
    "y_test = class_test.replace(to_replace = \"Distribution\", value = 1)\n",
    "y_test  = y_test.replace(to_replace = \"Other\", value = 0)\n",
    "y_test  = y_test.values\n",
    "\n",
    "X_full = tfidf.transform(full['processed_string'])\n",
    "X_full = X_full.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacked Classifier (tfidfVectorizer)\n",
    "## Using Logistic Regression as meta_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-fold cross validation:\n",
      "\n",
      "5-fold cross validated Accuracy: 0.87 (+/- 0.05) [Multinomial Naive Bayes]\n",
      "5-fold cross validated Accuracy: 0.87 (+/- 0.01) [Logistic Regression]\n",
      "5-fold cross validated Accuracy: 0.87 (+/- 0.01) [Linear SVC]\n",
      "5-fold cross validated Accuracy: 0.87 (+/- 0.01) [Random Forest Classifier]\n",
      "5-fold cross validated Accuracy: 0.91 (+/- 0.01) [XGBoost]\n",
      "5-fold cross validated Accuracy: 0.91 (+/- 0.01) [StackingClassifier]\n",
      "\n",
      "\n",
      "Stacked Classifier (TF-IDF) Clasification Report (Logistic Regression as meta classifier)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Distribution       0.60      0.33      0.43         9\n",
      "       Other       0.85      0.95      0.90        37\n",
      "\n",
      "    accuracy                           0.83        46\n",
      "   macro avg       0.73      0.64      0.66        46\n",
      "weighted avg       0.80      0.83      0.81        46\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from ThematicTextClassify.EnsembleClassifiers import *\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "stack_clf1 = MultinomialNB(alpha=0.25)\n",
    "stack_clf2 = LogisticRegression(C=0.25, penalty = 'l1')\n",
    "stack_clf3 = SVC(kernel='linear', C= 0.05, probability=True)\n",
    "stack_clf4 = RandomForestClassifier(max_depth =4, n_estimators = 300, random_state = 3)\n",
    "stack_clf5 =  XGBClassifier(max_depth = 7, seed = 2, random_state=1995,colsample_bytree=0.3, subsample=0.7)\n",
    "\n",
    "meta_clf = LogisticRegression(C=0.25, penalty = 'l1')\n",
    "sclf_tfidf = StackingClassifier(classifiers=[stack_clf1, stack_clf2, stack_clf3, stack_clf4, stack_clf5],\n",
    "                          use_probas=True,\n",
    "                          average_probas=False,\n",
    "                          meta_classifier=meta_clf)\n",
    "classifiers = [stack_clf1, stack_clf2, stack_clf3, stack_clf4, stack_clf5, sclf_tfidf]\n",
    "classifier_names = ['Multinomial Naive Bayes', 'Logistic Regression', 'Linear SVC', 'Random Forest Classifier','XGBoost', 'StackingClassifier']\n",
    "\n",
    "# Acuracy function (5-fold Cross validated)\n",
    "scoring(classifiers, classifier_names, X_train, y_train)\n",
    "\n",
    "\n",
    "# Predicting new data\n",
    "sclf_tfidf = sclf_tfidf.fit(X_train,y_train)\n",
    "prediction_results_int = sclf_tfidf.predict(X_test)\n",
    "prediction_results = []\n",
    "\n",
    "for i in prediction_results_int:\n",
    "    if i == 1:\n",
    "        prediction_results.append('Distribution')\n",
    "    else:\n",
    "        prediction_results.append('Other')\n",
    "\n",
    "# Print out Classification report\n",
    "print(\"\\n\")\n",
    "print(\"Stacked Classifier (TF-IDF) Clasification Report (Logistic Regression as meta classifier)\")\n",
    "print(classification_report(class_test.tolist(), prediction_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacked Classifier (tfidfVectorizer)\n",
    "## Using XGboost n as meta_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-fold cross validation:\n",
      "\n",
      "5-fold cross validated Accuracy: 0.87 (+/- 0.05) [Multinomial Naive Bayes]\n",
      "5-fold cross validated Accuracy: 0.87 (+/- 0.01) [Logistic Regression]\n",
      "5-fold cross validated Accuracy: 0.87 (+/- 0.01) [Linear SVC]\n",
      "5-fold cross validated Accuracy: 0.87 (+/- 0.01) [Random Forest Classifier]\n",
      "5-fold cross validated Accuracy: 0.91 (+/- 0.01) [XGBoost]\n",
      "5-fold cross validated Accuracy: 0.91 (+/- 0.05) [StackingClassifier]\n",
      "\n",
      "\n",
      "Stacked Classifier (TF-IDF) Clasification Report (XGBoost as Meta Classifier)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Distribution       0.38      0.33      0.35         9\n",
      "       Other       0.84      0.86      0.85        37\n",
      "\n",
      "    accuracy                           0.76        46\n",
      "   macro avg       0.61      0.60      0.60        46\n",
      "weighted avg       0.75      0.76      0.76        46\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from ThematicTextClassify.EnsembleClassifiers import *\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "stack_clf1 = MultinomialNB(alpha=0.25)\n",
    "stack_clf2 = LogisticRegression(C=0.25, penalty = 'l1')\n",
    "stack_clf3 = SVC(kernel='linear', C= 0.05, probability=True)\n",
    "stack_clf4 = RandomForestClassifier(max_depth =4, n_estimators = 300, random_state = 3)\n",
    "stack_clf5 =  XGBClassifier(max_depth = 7, seed = 2, random_state=1995,colsample_bytree=0.3, subsample=0.7)\n",
    "\n",
    "meta_clf = XGBClassifier(max_depth = 7, seed = 2, random_state=1995,colsample_bytree=0.3, subsample=0.7)\n",
    "\n",
    "sclf_XGB_tfidf  = StackingClassifier(classifiers=[stack_clf1, stack_clf2, stack_clf3, stack_clf4,stack_clf5],\n",
    "                          use_probas=True,\n",
    "                          average_probas=False,\n",
    "                          meta_classifier=meta_clf)\n",
    "classifiers = [stack_clf1, stack_clf2, stack_clf3, stack_clf4, stack_clf5, sclf_XGB_tfidf ]\n",
    "classifier_names = ['Multinomial Naive Bayes', 'Logistic Regression', 'Linear SVC', 'Random Forest Classifier', 'XGBoost','StackingClassifier']\n",
    "\n",
    "# Acuracy function (5-fold Cross validated)\n",
    "scoring(classifiers, classifier_names, X_train, y_train)\n",
    "\n",
    "# Predicting new data\n",
    "sclf_XGB_tfidf  = sclf_XGB_tfidf.fit(X_train,y_train)\n",
    "prediction_results_int = sclf_XGB_tfidf.predict(X_test)\n",
    "prediction_results = []\n",
    "\n",
    "for i in prediction_results_int:\n",
    "    if i == 1:\n",
    "        prediction_results.append('Distribution')\n",
    "    else:\n",
    "        prediction_results.append('Other')\n",
    "\n",
    "# Print Classification report    \n",
    "print(\"\\n\")\n",
    "print(\"Stacked Classifier (TF-IDF) Clasification Report (XGBoost as Meta Classifier)\")\n",
    "print(classification_report(class_test.tolist(), prediction_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voting Classifier (tfidfVectorizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-fold cross validation:\n",
      "\n",
      "5-fold cross validated Accuracy: 0.87 (+/- 0.05) [Multinomial Naive Bayes]\n",
      "5-fold cross validated Accuracy: 0.87 (+/- 0.01) [Logistic Regression]\n",
      "5-fold cross validated Accuracy: 0.87 (+/- 0.01) [Linear SVC]\n",
      "5-fold cross validated Accuracy: 0.87 (+/- 0.01) [Random Forest Classifier]\n",
      "5-fold cross validated Accuracy: 0.91 (+/- 0.01) [XGBoost]\n",
      "5-fold cross validated Accuracy: 0.87 (+/- 0.01) [VotingClassifier]\n",
      "\n",
      "\n",
      "Voting Classifier (TF-IDF) Clasification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Distribution       0.00      0.00      0.00         9\n",
      "       Other       0.80      1.00      0.89        37\n",
      "\n",
      "    accuracy                           0.80        46\n",
      "   macro avg       0.40      0.50      0.45        46\n",
      "weighted avg       0.65      0.80      0.72        46\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chi/anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/chi/anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/chi/anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "vote_clf1 = MultinomialNB(alpha=0.25)\n",
    "vote_clf2 = LogisticRegression(C=0.25, penalty = 'l1')\n",
    "vote_clf3 = LinearSVC(C=0.05, max_iter = 3000)\n",
    "vote_clf4 = RandomForestClassifier(max_depth =4, n_estimators = 300, random_state = 3)\n",
    "vote_clf5 = XGBClassifier(max_depth = 7, seed = 2, random_state=1995,colsample_bytree=0.3, subsample=0.7)\n",
    "\n",
    "eclf1_tfidf = VotingClassifier(estimators=[('Multinomial Naive Bayes', vote_clf1), ('Logistic Regression Classifier', vote_clf2), ('LinearSVC', vote_clf3), ('RandomForestClassifier', vote_clf4), ('XGBoost', vote_clf5)], voting='hard')\n",
    "eclf1_tfidf = eclf1_tfidf.fit(X_train, y_train)\n",
    "\n",
    "classifiers = [vote_clf1, vote_clf2, vote_clf3, vote_clf4,vote_clf5, eclf1_tfidf]\n",
    "classifier_names = ['Multinomial Naive Bayes', 'Logistic Regression', 'Linear SVC', 'Random Forest Classifier','XGBoost', 'VotingClassifier']\n",
    "\n",
    "# Acuracy function (5-fold Cross validated)\n",
    "scoring(classifiers, classifier_names, X_train, y_train)\n",
    "    \n",
    "# Predicting new data \n",
    "predicted = eclf1_tfidf.predict(X_test)\n",
    "eclf1_tfidf.score(X_test, y_test)\n",
    "\n",
    "pred_results = []\n",
    "for i in predicted:\n",
    "    if i == 1:\n",
    "        pred_results.append('Distribution')\n",
    "    else:\n",
    "        pred_results.append('Other')\n",
    "\n",
    "# Print Classification report\n",
    "print(\"\\n\")\n",
    "print(\"Voting Classifier (TF-IDF) Clasification Report\")\n",
    "print(classification_report(class_test.tolist(),pred_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appending the New Categories on to the Data set\n",
    "* We pick the one model that has the highest precision/f1-score to be our model \n",
    "* This model is `Stacked using logistic regression (tfidf)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Other           1653\n",
       "Distribution      44\n",
       "Name: BestModelClassification, dtype: int64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full['BestModelClassification'] = sclf_tfidf.predict(X_full)\n",
    "full['BestModelClassification'] = full['BestModelClassification'] .replace(to_replace = 1, value = \"Distribution\")\n",
    "full['BestModelClassification'] = full['BestModelClassification'] .replace(to_replace = 0, value = \"Other\")\n",
    "print(len(full[full['BestModelClassification'] == 'Distribution']))\n",
    "full['BestModelClassification'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = full[full['BestModelClassification'] == 'Distribution']\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"BestDistribution.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
